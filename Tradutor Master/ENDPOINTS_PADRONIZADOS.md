# âœ… Endpoints Padronizados - Testes Justos

## ðŸŽ¯ Garantia de ConsistÃªncia

Todos os fluxos de traduÃ§Ã£o agora usam **EXATAMENTE A MESMA CONFIGURAÃ‡ÃƒO** do Claude, garantindo testes justos e resultados consistentes.

## ðŸ“‹ Fluxos Padronizados

### 1. Arquivo Ãšnico (RealTimeTranslationWindow)
**Arquivo**: [src/ui.py](src/ui.py#L892-L900)

```python
translations, _ = self.claude_client.translate_document(
    tokens_data,
    source_lang,
    target_lang,
    dictionary,
    batch_size=None,      # Usa batch otimizado (40 para Haiku 3.5)
    progress_callback=None,
    use_parallel=True     # 15 workers paralelos para Haiku
)
```

### 2. MÃºltiplos Arquivos (BatchTranslationWindow)
**Arquivo**: [src/ui.py](src/ui.py#L994-L1002)

```python
translations, _ = self.claude_client.translate_document(
    tokens_data,
    source_lang,
    target_lang,
    dictionary,
    batch_size=None,      # Usa batch otimizado (40 para Haiku 3.5)
    progress_callback=None,
    use_parallel=True     # 15 workers paralelos para Haiku
)
```

### 3. TraduÃ§Ã£o com Pasta (Threading)
**Arquivo**: [src/ui.py](src/ui.py#L1210-L1218)

```python
translations, usage_stats = self.claude_client.translate_document(
    tokens_data,
    source_lang,
    target_lang,
    dictionary,
    batch_size=None,              # Usa batch otimizado (40 para Haiku 3.5)
    progress_callback=on_translation_progress,
    use_parallel=True             # 15 workers paralelos para Haiku
)
```

## âš™ï¸ ConfiguraÃ§Ã£o AutomÃ¡tica

Quando `batch_size=None` e `use_parallel=True`, o sistema automaticamente:

### Para Claude Haiku 3.5:
- âœ… **Batch size**: 40 tokens por requisiÃ§Ã£o
- âœ… **Workers**: 15 threads paralelas
- âœ… **Rate limit**: 50 RPM (monitorado automaticamente)
- âœ… **Processamento**: Paralelo quando `num_batches > 1`

### Para Claude Haiku 3:
- âœ… **Batch size**: 30 tokens por requisiÃ§Ã£o
- âœ… **Workers**: 15 threads paralelas
- âœ… **Rate limit**: 50 RPM

### Para Claude Sonnet 3.5:
- âœ… **Batch size**: 25 tokens por requisiÃ§Ã£o
- âœ… **Workers**: 8 threads paralelas
- âœ… **Rate limit**: 50 RPM

### Para Claude Opus 3:
- âœ… **Batch size**: 15 tokens por requisiÃ§Ã£o
- âœ… **Workers**: 8 threads paralelas
- âœ… **Rate limit**: 50 RPM

## ðŸ§ª Testes Justos Garantidos

### CenÃ¡rio 1: Traduzir 1 arquivo
```
Arquivo: contract.docx (200 parÃ¡grafos)

ConfiguraÃ§Ã£o usada:
  - Batch: 40 tokens
  - Workers: 15 paralelos
  - Batches criados: 200 Ã· 40 = 5
  - Processamento: PARALELO (5 batches simultÃ¢neos)
  - Tempo esperado: ~2.5 segundos
```

### CenÃ¡rio 2: Traduzir pasta com 5 arquivos
```
Arquivos: 5 contratos com 200 parÃ¡grafos cada

ConfiguraÃ§Ã£o usada (PARA CADA ARQUIVO):
  - Batch: 40 tokens
  - Workers: 15 paralelos
  - Batches por arquivo: 200 Ã· 40 = 5
  - Processamento: PARALELO (5 batches simultÃ¢neos por arquivo)
  - Tempo esperado: ~2.5 segundos Ã— 5 arquivos = ~12.5 segundos
```

### Resultado:
âœ… **MESMA VELOCIDADE** por arquivo, independente de ser Ãºnico ou em pasta!

## ðŸ“Š ComparaÃ§Ã£o de Performance

### ANTES da PadronizaÃ§Ã£o:
- Arquivo Ãºnico: poderia usar configuraÃ§Ã£o diferente
- MÃºltiplos arquivos: poderia usar outra configuraÃ§Ã£o
- **TESTES INJUSTOS** - resultados inconsistentes

### DEPOIS da PadronizaÃ§Ã£o:
- **TODOS os fluxos**: mesma configuraÃ§Ã£o
- **TODOS os arquivos**: mesma velocidade por arquivo
- **TESTES JUSTOS** - resultados consistentes

## ðŸ’¡ Como Funciona

### 1. Chamada do Endpoint
```python
# Qualquer fluxo chama assim:
translate_document(
    tokens_data,
    source_lang,
    target_lang,
    dictionary,
    batch_size=None,     # â† Usa configuraÃ§Ã£o otimizada
    progress_callback=...,
    use_parallel=True    # â† Ativa paralelismo
)
```

### 2. DetecÃ§Ã£o AutomÃ¡tica no ClaudeClient
```python
# claude_client.py detecta automaticamente:
if batch_size is None:
    batch_size = self.optimal_batch_size  # 40 para Haiku 3.5

if use_parallel and num_batches > 1:
    # Usar ThreadPoolExecutor com self.max_workers (15 para Haiku)
```

### 3. Resultado
- âœ… Sempre usa batch otimizado
- âœ… Sempre usa workers otimizados
- âœ… Sempre respeita rate limit
- âœ… Performance consistente

## âš¡ Performance Esperada

### Arquivo Individual (200 parÃ¡grafos):
```
ðŸ“¦ Dividindo 200 tokens em 5 batches de ~40 tokens
âš¡ Processamento PARALELO com 15 workers

  âœ“ Batch 1/5 completo - 48 req/min
  âœ“ Batch 2/5 completo - 50 req/min
  âœ“ Batch 3/5 completo - 49 req/min
  âœ“ Batch 4/5 completo - 50 req/min
  âœ“ Batch 5/5 completo - 50 req/min

âœ“ TraduÃ§Ã£o paralela completa: 200 tokens em 2.5s (50 req/min)
```

### Pasta com 5 Arquivos (200 parÃ¡grafos cada):
```
Arquivo 1/5:
  ðŸ“¦ Dividindo 200 tokens em 5 batches de ~40 tokens
  âš¡ Processamento PARALELO com 15 workers
  âœ“ TraduÃ§Ã£o completa: 2.5s

Arquivo 2/5:
  ðŸ“¦ Dividindo 200 tokens em 5 batches de ~40 tokens
  âš¡ Processamento PARALELO com 15 workers
  âœ“ TraduÃ§Ã£o completa: 2.5s

... (repetindo para arquivos 3, 4, 5)

Total: ~12.5 segundos para 5 arquivos
MÃ©dia: 2.5s por arquivo âœ“ CONSISTENTE
```

## âœ… Garantias

1. **Mesma configuraÃ§Ã£o** em todos os fluxos
2. **Mesma velocidade** por arquivo
3. **Mesmos logs** de processamento
4. **Mesmas mÃ©tricas** (RPM, batch size, workers)
5. **Testes justos** e comparÃ¡veis

## ðŸŽŠ ConclusÃ£o

Agora vocÃª pode:
- âœ… Traduzir 1 arquivo e medir a velocidade
- âœ… Traduzir uma pasta e comparar
- âœ… Ter certeza que a configuraÃ§Ã£o Ã© IDÃŠNTICA
- âœ… Testar com confianÃ§a que os resultados sÃ£o justos

**Todos os endpoints usam a mesma lÃ³gica otimizada!**
