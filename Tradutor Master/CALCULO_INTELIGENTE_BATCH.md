# ğŸ§® CÃ¡lculo Inteligente de Batch Size

## âœ… Implementado: CÃ¡lculo DinÃ¢mico Baseado no Tamanho Real

### âŒ Problema Anterior (Valores Fixos)

**ANTES**:
```python
OPTIMAL_BATCH_SIZES = {
    "claude-3-5-haiku-20241022": 80,  # FIXO para todos os documentos
}
```

**Problemas**:
- âŒ Textos curtos: Batch muito pequeno (desperdiÃ§a capacidade)
- âŒ Textos longos: Batch muito grande (excede max_tokens)
- âŒ NÃ£o considera tamanho real dos segmentos

**Exemplo do Problema**:
```
Documento A: Segmentos de 20 caracteres cada
  â†’ 80 segmentos Ã— 20 chars = 1,600 chars (MUITO PEQUENO, poderia enviar 200!)

Documento B: Segmentos de 300 caracteres cada
  â†’ 80 segmentos Ã— 300 chars = 24,000 chars (MUITO GRANDE, JSON cortado!)
```

### âœ… SoluÃ§Ã£o: CÃ¡lculo DinÃ¢mico

**AGORA**:
```python
# 1. Analisar primeiros 10 segmentos do documento
sample_size = min(10, len(tokens))
avg_text_length = sum(len(t["text"]) for t in tokens[:sample_size]) / sample_size

# 2. Estimar tokens por segmento
estimated_tokens_per_segment = (avg_text_length * 0.3) + 20

# 3. Calcular batch size ideal
safe_max_tokens = max_tokens * 0.85
batch_size = int(safe_max_tokens / estimated_tokens_per_segment)

# 4. Aplicar limites de seguranÃ§a
batch_size = max(20, min(batch_size, 80))
```

## ğŸ“Š Exemplos PrÃ¡ticos

### Documento com Textos Curtos (PO simples)

**Entrada**:
```
Segmentos: 500
Tamanho mÃ©dio: 30 caracteres
```

**CÃ¡lculo**:
```
ğŸ“Š CÃ¡lculo de batch size:
   Tamanho mÃ©dio dos textos: 30 caracteres
   Tokens estimados por segmento: 29 tokens (30 Ã— 0.3 + 20 JSON)
   Batch size calculado: 240 segmentos
   max_tokens disponÃ­vel: 8192 (usando 85% = 6963)

Aplicando limite mÃ¡ximo: 80 segmentos (limite de seguranÃ§a)
```

**Resultado**:
- Batches: 500 Ã· 80 = 7 batches
- Cada batch: ~2,320 tokens (dentro do limite!)

### Documento com Textos Longos (Contrato complexo)

**Entrada**:
```
Segmentos: 1500
Tamanho mÃ©dio: 250 caracteres
```

**CÃ¡lculo**:
```
ğŸ“Š CÃ¡lculo de batch size:
   Tamanho mÃ©dio dos textos: 250 caracteres
   Tokens estimados por segmento: 95 tokens (250 Ã— 0.3 + 20 JSON)
   Batch size calculado: 73 segmentos
   max_tokens disponÃ­vel: 8192 (usando 85% = 6963)

Batch size final: 73 segmentos (calculado automaticamente!)
```

**Resultado**:
- Batches: 1500 Ã· 73 = 21 batches
- Cada batch: ~6,935 tokens (dentro do limite!)

### Documento com Textos MUITO Longos (ClÃ¡usulas legais)

**Entrada**:
```
Segmentos: 800
Tamanho mÃ©dio: 400 caracteres
```

**CÃ¡lculo**:
```
ğŸ“Š CÃ¡lculo de batch size:
   Tamanho mÃ©dio dos textos: 400 caracteres
   Tokens estimados por segmento: 140 tokens (400 Ã— 0.3 + 20 JSON)
   Batch size calculado: 49 segmentos
   max_tokens disponÃ­vel: 8192 (usando 85% = 6963)

Batch size final: 49 segmentos
```

**Resultado**:
- Batches: 800 Ã· 49 = 17 batches
- Cada batch: ~6,860 tokens (PERFEITO!)

## ğŸ¯ FÃ³rmula Completa

```python
# Passo 1: Amostragem (10 primeiros segmentos)
sample = tokens[:10]

# Passo 2: Tamanho mÃ©dio em caracteres
avg_chars = mÃ©dia(len(seg["text"]) for seg in sample)

# Passo 3: Converter caracteres â†’ tokens
# Regra: 1 caractere â‰ˆ 0.3 tokens (portuguÃªs)
# + 20 tokens para JSON overhead {"location": "...", "translation": "..."}
tokens_per_segment = (avg_chars Ã— 0.3) + 20

# Passo 4: Calcular batch size
# 85% do max_tokens para margem de seguranÃ§a
safe_max = max_tokens Ã— 0.85
batch_size = safe_max Ã· tokens_per_segment

# Passo 5: Limites de seguranÃ§a
batch_size = max(20, min(batch_size, 80))
```

## ğŸ“ˆ ComparaÃ§Ã£o: Fixo vs DinÃ¢mico

| Tipo de Documento | Tamanho MÃ©dio | Batch Fixo | Batch DinÃ¢mico | DiferenÃ§a |
|-------------------|---------------|------------|----------------|-----------|
| PO simples | 30 chars | 80 | 80 (limite max) | âœ“ Otimizado |
| Contrato mÃ©dio | 150 chars | 80 | 65 | âœ“ Melhor |
| Contrato longo | 250 chars | 80 | 73 | âœ“ Evita erro! |
| ClÃ¡usulas legais | 400 chars | 80 | 49 | âœ“âœ“ Salva de erro! |
| Texto tÃ©cnico | 500 chars | 80 | 38 | âœ“âœ“âœ“ Previne corte! |

## ğŸ” Logs que VocÃª VerÃ¡

### Antes de Traduzir

```
ğŸ“Š CÃ¡lculo de batch size:
   Tamanho mÃ©dio dos textos: 245 caracteres
   Tokens estimados por segmento: 94 tokens
   Batch size calculado: 74 segmentos
   max_tokens disponÃ­vel: 8192 (usando 85% = 6963)

================================================================================
ğŸ“¦ ESTRATÃ‰GIA DE TRADUÃ‡ÃƒO:
   Total de segmentos: 1484
   Segmentos por requisiÃ§Ã£o: ~74
   NÃºmero de requisiÃ§Ãµes: 21
   Modo: SEQUENCIAL (1 worker)
   ğŸ’¡ Cada requisiÃ§Ã£o traduz ~74 segmentos de uma sÃ³ vez!
================================================================================
```

### Durante TraduÃ§Ã£o (AtualizaÃ§Ã£o em Tempo Real)

```
Claude: 0/1484 segmentos traduzidos (Batch 1/21)
  ğŸ“¤ Enviando 74 segmentos numa ÃšNICA requisiÃ§Ã£o para Claude...
  ğŸ“¥ Resposta recebida do Claude para os 74 segmentos
Claude: 74/1484 segmentos traduzidos âœ“

Claude: 74/1484 segmentos traduzidos (Batch 2/21)
  ğŸ“¤ Enviando 74 segmentos numa ÃšNICA requisiÃ§Ã£o para Claude...
  ğŸ“¥ Resposta recebida do Claude para os 74 segmentos
Claude: 148/1484 segmentos traduzidos âœ“

Claude: 148/1484 segmentos traduzidos (Batch 3/21)
  ğŸ“¤ Enviando 74 segmentos numa ÃšNICA requisiÃ§Ã£o para Claude...
  ğŸ“¥ Resposta recebida do Claude para os 74 segmentos
Claude: 222/1484 segmentos traduzidos âœ“
```

## âœ… BenefÃ­cios

1. **Adaptativo**: Ajusta automaticamente ao tipo de documento
2. **Seguro**: Sempre fica dentro do limite de max_tokens
3. **Eficiente**: Usa mÃ¡xima capacidade possÃ­vel sem desperdiÃ§ar
4. **Tempo Real**: Interface atualiza a cada batch completado
5. **Sem Erros**: NÃ£o corta mais JSONs no meio

## ğŸ“ Por Que 85% do max_tokens?

```
max_tokens = 8192

USAR 100% (8192):
  âŒ Qualquer variaÃ§Ã£o no tamanho = JSON cortado
  âŒ Overhead de formataÃ§Ã£o pode exceder
  âŒ Risco alto

USAR 85% (6963):
  âœ… Margem de seguranÃ§a de 15%
  âœ… Absorve variaÃ§Ãµes de tamanho
  âœ… Garante JSON completo
  âœ… Ainda usa ~87% da capacidade
```

## ğŸ“Š Amostragem de 10 Segmentos

**Por que 10?**
```
Menos de 10:
  âŒ Amostra muito pequena
  âŒ Pode nÃ£o ser representativa

Exatamente 10:
  âœ… RÃ¡pido de calcular
  âœ… Estatisticamente significativo
  âœ… Representa bem o documento

Mais de 10:
  âœ… Mais preciso
  âŒ Overhead desnecessÃ¡rio
```

## ğŸ”§ Arquivos Modificados

- **[src/claude_client.py](src/claude_client.py#L178-L198)**: CÃ¡lculo inteligente de batch size
- **[src/claude_client.py](src/claude_client.py#L264-L288)**: AtualizaÃ§Ã£o em tempo real

---

**Resumo**: Agora o batch size Ã© **calculado dinamicamente** baseado no tamanho real dos textos, garantindo mÃ¡xima eficiÃªncia sem erros! ğŸš€
